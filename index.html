<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Erroll Wood</title>
    <link rel="shortcut icon" type="image/jpg" href="img/favicon.ico" />
    <link rel="stylesheet" href="css/styles.css">
</head>

<body>
    <section class="section pb-0">
        <div class="container is-max-desktop">
            <div class="columns">
                <div class="column is-one-quarter is-two-thirds-mobile is-offset-2-mobile">
                    <figure class="image">
                        <img src="img/erroll_wood_2_512.jpg">
                    </figure>
                </div>
                <div class="column">
                    <div class="content">
                        <h1 class="title is-3">
                            Erroll Wood
                        </h1>
                        <p>I am a Staff Software Engineer working at <a href="https://blog.google/products/google-ar-vr/building-and-testing-helpful-ar-experiences/"><b><span style="color: #4285F4">G</span><span style="color: #DB4437">o</span><span style="color: #F4B400">o</span><span style="color: #4285F4">g</span><span style="color: #0F9D58">l</span><span style="color: #DB4437">e</span> AR &amp; VR</b></a> on Digital Humans.</p>
                        <p>Previously, I was a Principal Scientist at Microsoft's <a href="https://www.microsoft.com/en-us/research/lab/mixed-reality-ai-lab-cambridge">MR &amp; AI Lab</a> in Cambridge, UK where I worked on
                            <a href="https://youtu.be/4rRF4UMppjY?t=43">hand tracking for HoloLens 2</a>, <a href="https://youtu.be/5UIUy1QGX8Q?t=203">avatars for Microsoft Mesh</a>,
                            <a href="https://microsoft.github.io/FaceSynthetics/">synthetic data for face tracking</a>, and Holoportation. I did my PhD at the <a href="https://www.cl.cam.ac.uk/research/rainbow/">University of Cambridge</a>, working
                            on
                            <a href="pdf/eww23_phd.pdf">gaze estimation</a>.
                        </p>
                        <p><a href="mailto:errollw@gmail.com">errollw@gmail.com</a>&ensp;|&ensp;<a href="https://scholar.google.co.uk/citations?user=iquixu4AAAAJ&hl=en">Google Scholar</a>&ensp;|&ensp;<a href="https://www.linkedin.com/in/erroll-wood/">LinkedIn</a></p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section class="section">
        <div class="container is-max-desktop">
            <div class="content">
                <h1 class="title is-4">
                    Research
                </h1>
                <!-- <p>I'm interested in computer vision, graphics, and deep learning. Much of my work involves helping Mixed Reality devices better understand humans, in real time.</p> -->
            </div>
            <div class="columns has-background-warning-light">
                <div class="column is-one-quarter">
                    <figure class="image">
                        <a href="https://www.youtube.com/watch?v=M8NNytHysVg"><img src="img/dense-landmarks.png"></a>
                    </figure>
                </div>
                <aside class="column">
                    <p><a href="https://arxiv.org/abs/2204.02776">3D Face Reconstruction with Dense Landmarks</a></p>
                    <p>
                        <b>Erroll Wood</b>, Tadas Baltrušaitis, Charlie Hewitt, Matthew Johnson, Jingjing Shen, Nikola Milosavljević, Daniel Wilde, Stephan Garbin, Chirag Raman, Jamie Shotton, Toby Sharp, Ivan Stojiljković, Tom Cashman, Julien Valentin
                    </p>
                    <p><i>ECCV 2022</i></p>
                    <p><a href="https://arxiv.org/abs/2204.02776">paper</a>&ensp;|&ensp;<a href="https://www.youtube.com/watch?v=M8NNytHysVg">video</a>&ensp;|&ensp;<a href="https://microsoft.github.io/DenseLandmarks/">project page</a></p>
                </aside>
            </div>
            <div class="columns">
                <div class="column is-one-quarter">
                    <figure class="image">
                        <a href="https://microsoft.github.io/FaceSynthetics/"><img src="img/fake-it-iccv2021.png"></a>
                    </figure>
                </div>
                <aside class="column">
                    <p><a href="https://microsoft.github.io/FaceSynthetics/">Fake It Till You Make It: Face analysis in the wild using synthetic data alone</a></p>
                    <p>
                        <b>Erroll Wood*</b>, Tadas Baltrušaitis*, Charlie Hewitt, Sebastian Dziadzio, Matthew Johnson, Virginia Estellers, Thomas J. Cashman, Jamie Shotton
                    </p>
                    <p><i>ICCV 2021</i></p>
                    <p><a href="https://arxiv.org/abs/2109.15102">paper</a>&ensp;|&ensp;<a href="https://www.youtube.com/watch?v=wlOMpQe8luQ">video</a>&ensp;|&ensp;<a href="https://microsoft.github.io/FaceSynthetics/">project page</a></p>
                </aside>
            </div>
            <div class="columns">
                <div class="column is-one-quarter">
                    <figure class="image">
                        <a href="https://www.youtube.com/watch?v=3ba1jlzuuPc"><img src="img/smpl_made_simple_cvpr2021.png"></a>
                    </figure>
                </div>
                <aside class="column">
                    <p><a href="https://www.youtube.com/watch?v=3ba1jlzuuPc">SMPL in Mixed Reality at Microsoft</a> </p>
                    <p><b>Erroll Wood</b>, Federica Bogo, Tom Cashman</p>
                    <p><i>SMPL Made Simple Tutorial, CVPR 2021</i></p>
                    <p><a href="https://www.youtube.com/watch?v=3ba1jlzuuPc">video</a></a>&ensp;|&ensp;<a href="https://smpl-made-simple.is.tue.mpg.de/">tutorial page</a></p>
                </aside>
            </div>
            <div class="columns">
                <div class="column is-one-quarter">
                    <figure class="image">
                        <a href="https://www.youtube.com/watch?v=4rRF4UMppjY"><img src="img/synthetic_data_cvpr2021.png"></a>
                    </figure>
                </div>
                <aside class="column">
                    <p><a href="https://www.youtube.com/watch?v=4rRF4UMppjY">Synthetic Data with Digital Humans</a></p>
                    <p><b>Erroll Wood</b>, Tadas Baltrušaitis</p>
                    <p><i>Microsoft Sponsor Session, CVPR 2021</i></p>
                    <p><a href="https://www.youtube.com/watch?v=4rRF4UMppjY">video</a></p>
                </aside>
            </div>
            <div class="columns">
                <div class="column is-one-quarter">
                    <figure class="image">
                        <a href="https://www.youtube.com/watch?v=-tDaZk9V1Nw"><img src="img/gaze_director.png"></a>
                    </figure>
                </div>
                <aside class="column">
                    <p><a href="https://www.youtube.com/watch?v=-tDaZk9V1Nw">GazeDirector: Fully Articulated Eye Gaze Redirection in Video</a></p>
                    <p><b>Erroll Wood</b>, Tadas Baltrušaitis, Louis-Philippe Morency, Peter Robinson, Andreas Bulling</p>
                    <p><i>Eurographics 2018</i></p>
                    <p><a href="https://arxiv.org/pdf/1704.08763.pdf">paper</a>&ensp;|&ensp;<a href="https://www.youtube.com/watch?v=-tDaZk9V1Nw">video</a></p>
                </aside>
            </div>
            <div class="columns">
                <div class="column is-one-quarter">
                    <figure class="image">
                        <a href="https://www.youtube.com/watch?v=n_htSvUq7iU"><img src="img/eccv2016.jpg"></a>
                    </figure>
                </div>
                <aside class="column">
                    <p><a href="https://www.youtube.com/watch?v=n_htSvUq7iU">A 3D morphable eye region model for gaze estimation</a></p>
                    <p><b>Erroll Wood</b>, Tadas Baltrušaitis, Louis-Philippe Morency, Peter Robinson, Andreas Bulling</p>
                    <p><i>ECCV 2016</i></p>
                    <p><a href="pdf/eccv2016.pdf">paper</a>&ensp;|&ensp;<a href="https://www.youtube.com/watch?v=n_htSvUq7iU">video</a></p>
                </aside>
            </div>
            <div class="columns">
                <div class="column is-one-quarter">
                    <figure class="image">
                        <a href="https://www.youtube.com/watch?v=QTz1zQAnMcU"><img src="img/siggraph2016.png"></a>
                    </figure>
                </div>
                <aside class="column">
                    <p><a href="https://www.youtube.com/watch?v=QTz1zQAnMcU">Efficient and Precise Interactive Hand Tracking Through Joint, Continuous Optimization of Pose and Correspondences</a></p>
                    <p>J. Taylor, L. Bordeaux, T. Cashman, B. Corish, C. Keskin, T. Sharp, E. Soto, D. Sweeney, J. Valentin, B. Luff, A. Topalian, <b>E. Wood</b>, S. Khamis, P. Kohli, S. Izadi, R. Banks, A. Fitzgibbon, J. Shotton, <i>SIGGRAPH 2016</i></p>
                    <p><a href="pdf/siggraph2016.pdf">paper</a>&ensp;|&ensp;<a href="https://www.youtube.com/watch?v=QTz1zQAnMcU">video</a>&ensp;|&ensp;<a href="https://blogs.microsoft.com/ai/talking-hands-microsoft-researchers-moving-beyond-keyboard-mouse/">blog</a></p>
                </aside>
            </div>
            <div class="columns">
                <div class="column is-one-quarter">
                    <figure class="image">
                        <a href="https://www.cl.cam.ac.uk/research/rainbow/projects/unityeyes/"><img src="img/etra2016.jpg"></a>
                    </figure>
                </div>
                <aside class="column">
                    <p><a href="https://www.cl.cam.ac.uk/research/rainbow/projects/unityeyes/">Learning an Appearance-based Gaze Estimator from One Million Synthesized Images</a></p>
                    <p><b>Erroll Wood</b>, Tadas Baltrušaitis, Louis-Philippe Morency, Peter Robinson, Andreas Bulling<br/></p>
                    <p><i>Eye-Tracking Research &amp; Applications (ETRA) 2016</i></p>
                    <p><a href="pdf/etra2016.pdf">paper</a>&ensp;|&ensp;<a href="https://www.cl.cam.ac.uk/research/rainbow/projects/unityeyes/">project page</a></p>
                </aside>
            </div>
            <div class="columns">
                <div class="column is-one-quarter">
                    <figure class="image">
                        <a href="https://www.youtube.com/watch?v=q1Jmo5z0K08"><img src="img/iccv2015.jpg"></a>
                    </figure>
                </div>
                <aside class="column">
                    <p><a href="https://www.youtube.com/watch?v=q1Jmo5z0K08">Rendering of Eyes for Eye-Shape Registration and Gaze Estimation</a></p>
                    <p><b>Erroll Wood</b>, Tadas Baltrušaitis, Xucong Zhang, Yusuke Sugano, Peter Robinson, Andreas Bulling<br/></p>
                    <p><i>ICCV 2015</i></p>
                    <p><a href="pdf/iccv2015.pdf">paper</a>&ensp;|&ensp;<a href="https://www.youtube.com/watch?v=q1Jmo5z0K08">video</a>&ensp;|&ensp;<a href="http://www.cl.cam.ac.uk/research/rainbow/projects/syntheseyes/">project page</a></p>
                </aside>
            </div>
        </div>
    </section>
    <footer class="footer">
        <div class="content has-text-centered">
            <p><a href="mailto:errollw@gmail.com">errollw@gmail.com</a>&ensp;|&ensp;<a href="https://scholar.google.co.uk/citations?user=iquixu4AAAAJ&hl=en">Google Scholar</a>&ensp;|&ensp;<a href="https://www.linkedin.com/in/erroll-wood/">LinkedIn</a></p>
        </div>
    </footer>
</body>

<script>
    document.addEventListener('DOMContentLoaded', () => {

        // Get all "navbar-burger" elements
        const $navbarBurgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0);

        // Check if there are any navbar burgers
        if ($navbarBurgers.length > 0) {

            // Add a click event on each of them
            $navbarBurgers.forEach(el => {
                el.addEventListener('click', () => {

                    // Get the target from the "data-target" attribute
                    const target = el.dataset.target;
                    const $target = document.getElementById(target);

                    // Toggle the "is-active" class on both the "navbar-burger" and the "navbar-menu"
                    el.classList.toggle('is-active');
                    $target.classList.toggle('is-active');

                });
            });
        }

        // Convert all PDF links to link to GitHub to get around LFS issues
        Array.from(document.querySelectorAll('a')).forEach(function(el) {
            var href = el.getAttribute('href');
            if (href.startsWith("pdf/")) {
                el.setAttribute('href', "https://github.com/errollw/website/raw/main/" + href);
            }
        });

    });
</script>

</html>